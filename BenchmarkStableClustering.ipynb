{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e44b1d-68f4-4f78-8a5d-bc7d1ca0967b",
   "metadata": {},
   "source": [
    "# Benchmark for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208974f3-ee65-40b7-93f2-4509a8e955b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load/import helper functions\"\"\"\n",
    "\n",
    "import time\n",
    "import random\n",
    "from LocalPopular import extract_labels_from_communities, time_tester, calculate_scores_clustering\n",
    "\n",
    "from LocalStable import locally_stable_clustering_with_euclid_graphs\n",
    "\n",
    "from GraphFunctions import generate_agents, calculate_euclidian_relationships, create_graph, \\\n",
    "    my_make_circles, create_graphs_euclid, create_graphs_kNN, \\\n",
    "    generate_graph,create_graphs_hop_distance, create_graphs_hop_distance_abs,randomize_graph_pos_labels\n",
    "\n",
    "import importlib\n",
    "import PlotHelperFunctions\n",
    "importlib.reload(PlotHelperFunctions)\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.datasets import make_moons, load_breast_cancer, load_iris\n",
    "from sklearn.metrics import rand_score\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from community_detection.leiden import leiden\n",
    "from community_detection.louvain import louvain\n",
    "from community_detection.quality_functions import CPM, Modularity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee4aa8-710f-4218-bb3d-9c7585dd1700",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed85ce8-b19f-45fe-9513-67370e7d2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moon Dataset\n",
    "moon_agents,moon_truth = make_moons(n_samples=300, noise=0.05)\n",
    "\n",
    "# Circle Dataset\n",
    "circle_agents, circle_truth = my_make_circles(300)\n",
    "\n",
    "# Cancer Dataset\n",
    "cancer = load_breast_cancer()\n",
    "cancer_agents = cancer['data']\n",
    "cancer_truth = cancer['target']\n",
    "\n",
    "# Iris Dataset\n",
    "iris = load_iris()\n",
    "iris_agents = iris['data']\n",
    "iris_truth = iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80dffb-566a-4315-a94d-d10b01ff9805",
   "metadata": {},
   "source": [
    "## Run the algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cf013-12b0-4c38-bd4b-42a32d22ee24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "import numbers\n",
    "\n",
    "dfs = []\n",
    "labels = [(0.2,0.2), (0.25,0.35),(0.4,0.4)]\n",
    "\n",
    "for treshold in labels:\n",
    "    collected_data = {}\n",
    "    for repetitions in range(10):\n",
    "        f = treshold[0]   #f-bound\n",
    "        e = treshold[1]   \n",
    "\n",
    "        data = [ moon_agents,circle_agents,cancer_agents,iris_agents]\n",
    "        expected_clusters = [2,3,2,3]\n",
    "        graph_names = ['Moons','3 Circles', 'Cancer', 'Iris']\n",
    "        graph_truths =  [moon_truth,circle_truth,cancer_truth,iris_truth]\n",
    "        \n",
    "        \n",
    "        kmeans = lambda agents, clusters: KMeans(n_clusters = clusters).fit_predict(agents)\n",
    "        dbscan = lambda agents, clusters: DBSCAN(eps=0.2, min_samples=5).fit_predict(agents)\n",
    "        \n",
    "        kmeans_out = None\n",
    "        dbscan_out = None\n",
    "        \n",
    "        lp_a_b =lambda agents, initial_clustering, pre, allow_exit: locally_stable_clustering_with_euclid_graphs(agents, f, e, initial_clustering,allow_exit,mode='B',pre=pre)\n",
    "        lp_a_f =lambda agents, initial_clustering, pre, allow_exit: locally_stable_clustering_with_euclid_graphs(agents, f, e, initial_clustering, allow_exit, mode='F',pre=pre)\n",
    "        lp_a_e =lambda agents, initial_clustering, pre, allow_exit: locally_stable_clustering_with_euclid_graphs(agents, f, e, initial_clustering, allow_exit, mode='E',pre=pre)\n",
    "        \n",
    "        algorithms = [ kmeans, dbscan,lp_a_b,lp_a_f,lp_a_e]\n",
    "        algo_names = [ 'kmeans', 'dbscan','LS (Balanced) Heuristic',\\\n",
    "                       'LS (Friend-Oriented) Heuristic','LS (Enemy-Averse) Heuristic']\n",
    "        is_lp_heuristic = [False,False,True, True, True]\n",
    "        \n",
    "       \n",
    "\n",
    "        for ((graph, g_name,clusters,truth), (algo, a_name,lp_heuristic)) in \\\n",
    "            itertools.product(zip(data, graph_names, expected_clusters,graph_truths), zip(algorithms, algo_names,is_lp_heuristic)):\n",
    "\n",
    "            graph,truth = randomize_graph_pos_labels(graph,truth)\n",
    "\n",
    "            graph = [graph]\n",
    "            truth = [truth]\n",
    "                \n",
    "            agents = graph\n",
    "        \n",
    "            if lp_heuristic:\n",
    "                # start with everyone alone\n",
    "                a_name_modified = a_name + ' starting with everyone alone'\n",
    "                allow_exit = False\n",
    "                test_callable = lambda a: list(algo(a,len(agents[0]),None,allow_exit).values())\n",
    "                times,outputs = time_tester(test_callable,graph)\n",
    "                avg_time = sum(times)/len(times)\n",
    "                scores = calculate_scores_clustering(outputs,truth,agents)\n",
    "                scores['Time'] = avg_time\n",
    "        \n",
    "                if (a_name_modified, g_name) not in collected_data:\n",
    "                    collected_data[(a_name_modified, g_name)] = []\n",
    "                collected_data[(a_name_modified, g_name)].append(scores)\n",
    "        \n",
    "                # start with random clustering \n",
    "        \n",
    "                a_name_modified = a_name + ' starting with predicted number of clusters'\n",
    "                allow_exit = False\n",
    "                test_callable = lambda a: list(algo(a,clusters,None,allow_exit).values())\n",
    "                times,outputs = time_tester(test_callable,graph)\n",
    "                avg_time = sum(times)/len(times)\n",
    "                scores = calculate_scores_clustering(outputs,truth,agents)\n",
    "                scores['Time'] = avg_time\n",
    "        \n",
    "                if (a_name_modified, g_name) not in collected_data:\n",
    "                    collected_data[(a_name_modified, g_name)] = []\n",
    "                collected_data[(a_name_modified, g_name)].append(scores)\n",
    "        \n",
    "        \n",
    "                # start with the output of k-means\n",
    "                a_name_modified = a_name + ' starting with the output of k-means'\n",
    "                allow_exit = False\n",
    "                test_callable = lambda a: list(algo(a,clusters,kmeans,allow_exit).values())\n",
    "                times,outputs = time_tester(test_callable,graph)\n",
    "                avg_time = sum(times)/len(times)\n",
    "                scores = calculate_scores_clustering(outputs,truth,agents)\n",
    "        \n",
    "                rand_score_with_init = sum(rand_score(out, k) for out, k in zip(outputs, kmeans_out)) / len(outputs)\n",
    "                scores['Rand Score with initial clustering'] = rand_score_with_init\n",
    "                \n",
    "                scores['Time'] = avg_time\n",
    "\n",
    "                if (a_name_modified, g_name) not in collected_data:\n",
    "                    collected_data[(a_name_modified, g_name)] = []\n",
    "                collected_data[(a_name_modified, g_name)].append(scores)\n",
    "        \n",
    "                # start with the output of dbscan\n",
    "                allow_exit = False\n",
    "                test_callable = lambda a: list(algo(a,clusters,dbscan,allow_exit).values())\n",
    "                times,outputs = time_tester(test_callable,graph)\n",
    "                avg_time = sum(times)/len(times)\n",
    "                scores = calculate_scores_clustering(outputs,truth,agents)\n",
    "        \n",
    "                rand_score_with_init = sum(rand_score(out, db) for out, db in zip(outputs, dbscan_out)) / len(outputs)\n",
    "                scores['Rand Score with initial clustering'] = rand_score_with_init\n",
    "                   \n",
    "                scores['Time'] = avg_time\n",
    "        \n",
    "                if (a_name_modified, g_name) not in collected_data:\n",
    "                    collected_data[(a_name_modified, g_name)] = []\n",
    "                collected_data[(a_name_modified, g_name)].append(scores)\n",
    "\n",
    "            \n",
    "            else:\n",
    "        \n",
    "                test_callable = lambda a : algo(a, clusters)\n",
    "                    \n",
    "                times,outputs = time_tester(test_callable,graph)\n",
    "                if(algo == kmeans):\n",
    "                    kmeans_out = outputs\n",
    "                if(algo == dbscan):\n",
    "                    dbscan_out = outputs\n",
    "                avg_time = sum(times)/len(times)\n",
    "                scores = calculate_scores_clustering(outputs,truth,agents)\n",
    "                scores['Time'] = avg_time\n",
    "                \n",
    "                if (a_name, g_name) not in collected_data:\n",
    "                    collected_data[(a_name, g_name)] = []\n",
    "                collected_data[(a_name, g_name)].append(scores)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for (method, dataset), metrics_list in collected_data.items():\n",
    "        record = {'Method': method, 'Dataset': dataset}\n",
    "        keys = metrics_list[0].keys()\n",
    "        for key in keys:\n",
    "            # check if this metric is numeric\n",
    "            if isinstance(metrics_list[0][key], numbers.Number):\n",
    "                values = [m[key] for m in metrics_list]\n",
    "                mean = sum(values) / len(values)\n",
    "                std = (sum((v - mean) ** 2 for v in values) / len(values)) ** 0.5\n",
    "                record[key] = (mean, std)\n",
    "            else:\n",
    "                # if not numeric (e.g., a string), just copy one of them\n",
    "                record[key] = metrics_list[0][key]\n",
    "        records.append(record)\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1986e-03bf-44e0-991b-6932e8247fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6dbccb0-f912-47c3-93a1-aba2be75fd89",
   "metadata": {},
   "source": [
    "## Gather the numbers\n",
    "\n",
    "We can use the collected_data dictionairy to build a table for better comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd218f7e-c7da-43cd-9b0a-e9585863f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximum standart deviations\n",
    "max_stds = {}\n",
    "\n",
    "for df in dfs:\n",
    "    for col in ['Rand Index', 'Silhouette Score']:\n",
    "        stds = df[col].apply(lambda x: x[1] if isinstance(x, (tuple, list)) else float('nan'))\n",
    "        max_stds[col] = max(max_stds.get(col, float('-inf')), stds.max())\n",
    "\n",
    "print(max_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c947e2c-1f71-4627-9f5a-6473f69c6193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "score_cols = ['Rand Index', 'Silhouette Score']\n",
    "\n",
    "\n",
    "labels = [(0.2,0.2),(0.25,0.35),(0.4,.4)]\n",
    "# Plot the results\n",
    "for Dataset in ['Cancer', 'Iris', 'Moons', '3 Circles']:\n",
    "    for score in score_cols:\n",
    "        PlotHelperFunctions.plot_and_save_clustering(\n",
    "            dfs, labels, Dataset, score,\n",
    "            save_path=f'./figures/StableClustering/{Dataset}-{score}.png'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f09018-3457-4a7f-aea1-e6e4c57cabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Compute the mean Rand Scores with the initial clustering\n",
    "\n",
    "all_values = []\n",
    "\n",
    "for df in dfs:\n",
    "    col = 'Rand Score with initial clustering'\n",
    "    if col in df.columns:\n",
    "        values = df[col].apply(\n",
    "            lambda x: ast.literal_eval(x)[0] if isinstance(x, str) and x.startswith('(')\n",
    "            else x[0] if isinstance(x, (tuple, list))\n",
    "            else float('nan')\n",
    "        )\n",
    "        all_values.extend(values.dropna().tolist())\n",
    "\n",
    "# Convert to numpy array for convenience\n",
    "all_values = np.array(all_values)\n",
    "\n",
    "# Compute min, max, and average, ignoring NaNs\n",
    "min_val = np.nanmin(all_values)\n",
    "max_val = np.nanmax(all_values)\n",
    "avg_val = np.nanmean(all_values)\n",
    "\n",
    "print(f\"Min: {min_val}\")\n",
    "print(f\"Max: {max_val}\")\n",
    "print(f\"Average: {avg_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc06ca5-0203-414f-9344-0dbe39cec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(dfs):\n",
    "    df.to_csv(f'./csv/StableClustering/dataset-{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5a250-32d7-4380-9bf9-c7c8d4bc31e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
